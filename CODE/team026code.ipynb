{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user should provide the data paths. No other modifications to the code should be necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Data Source and destination of processed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data mangement: pelase update with your absolute paths\n",
    "datasource = 'C:/Users/User/Data/Houston/team026data.csv'\n",
    "datadestination = 'C:/Users/User/Data/Houston/team026cleandata.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "calls = pd.read_table(datasource, delimiter=',',low_memory=False)\n",
    "calls = calls.replace(np.nan, '', regex=True)\n",
    "calls[\"OVERDUE\"] = pd.to_numeric(calls[\"OVERDUE\"], downcast=\"float\")\n",
    "#Add Classes\n",
    "Classes = {'Traffic Signal Maintenance':'RoadServices','Street Hazard':'RoadServices','Traffic Signs':'RoadServices','Parking Violation':'RoadServices','Street Condition':'RoadServices','Pothole':'RoadServices','Traffic Signals':'RoadServices','Nuisance On Property':'Safety','Tree Trim':'Safety','Fire Hydrant':'Safety','MultiFamily Habitability Violation':'Safety','Missed Garbage Pickup':'Trash','Container Problem':'Trash','Missed Recycling Pickup':'Trash','Missed Heavy Trash Pickup':'Trash','Dead Animal Collection':'Trash','Heavy Trash Violation':'Trash','Trash Dumping or Illegal Dumpsite':'Trash','Recycling Cart Repair or Replace':'Trash','Recycling Participation NEW':'Trash','New Resident Container':'Trash','Missed Yard Waste Pickup':'Trash','Junk Motor Vehicle':'Trash','Storm Debris Collection':'Trash','Water Leak':'WaterUtility','Sewer Wastewater':'WaterUtility','Water Service':'WaterUtility','Drainage':'WaterUtility','SWM Escalation':'WaterUtility','Water Main Valve':'WaterUtility','Restoration Due To Utility Work':'WaterUtility'}\n",
    "def get_class(word,Classes):\n",
    "    if word in Classes.keys():\n",
    "        return Classes[word]\n",
    "    else:\n",
    "        return \"NI\"\n",
    "calls[\"Class\"] = calls['SR TYPE'].apply(lambda x:get_class(x,Classes))\n",
    "#Revise Neighborhood\n",
    "RevisedNeighborhoods = {'BRAESWOOD':'BRAESWOOD PLACE','BRIAR FOREST':'BRIARFOREST AREA','FORT BEND HOUSTON':'FORT BEND / HOUSTON','GREATER OST / SOUTH UNION':'OST / SOUTH UNION','LAZYBROOK / TIMBERGROVE':'LAZY BROOK / TIMBERGROVE','NEAR NORTHSIDE':'NORTHSIDE VILLAGE','NEAR SOUTHWEST':'WILLOW MEADOWS / WILLOWBEND AREA','WASHINGTON AVENUE COALITION / MEMORIAL P':'WASHINGTON AVENUE COALITION / MEMORIAL PARK'}\n",
    "def revise_neighborhood(neighborhood,RevisedNeighborhoods):\n",
    "    if neighborhood in RevisedNeighborhoods.keys():\n",
    "        return RevisedNeighborhoods[neighborhood].title()\n",
    "    else:\n",
    "        return neighborhood.title()\n",
    "calls[\"R_NEIGHBORHOOD\"] = calls['NEIGHBORHOOD'].apply(lambda x:revise_neighborhood(x,RevisedNeighborhoods))\n",
    "Population = {'Acres Home':25828, 'Addicks Park Ten':19683, 'Afton Oaks / River Oaks Area':14518, 'Alief':106657, 'Astrodome Area':18223, 'Braeburn':18843, 'Braeswood Place':21835, 'Brays Oaks':64548, 'Briarforest Area':43018, 'Carverdale':3903, 'Central Northwest':41993, 'Central Southwest':66918, 'Clear Lake':62268, 'Clinton Park Tri-Community':3140, 'Denver Harbor / Port Houston':17571, 'Downtown':12088, 'East Houston':18580, 'East Little York / Homestead':19607, 'Eastex - Jensen Area':25724, 'Edgebrook Area':23584, 'El Dorado / Oates Prairie':3852, 'Eldridge / West Oaks':72347, 'Fairbanks / Northwest Crossing':18007, 'Fondren Gardens':2730, 'Fort Bend / Houston':33630, 'Fourth Ward':4085, 'Golfcrest / Bellfort / Reveille':51432, 'Greater Eastwood':10776, 'Greater Fifth Ward':19687, 'Greater Greenspoint':41392, 'Greater Heights':41362, 'Greater Hobby Area':25385, 'Greater Inwood':37056, 'Greater Third Ward':14295, 'Greater Uptown':50731, 'Greenway / Upper Kirby Area':21120, 'Gulfgate Riverview / Pine Valley':12723, 'Gulfton':41089, 'Harrisburg / Manchester':2926, 'Hidden Valley':3569, 'Hunterwood':1951, 'Iah / Airport Area':15752, 'Independence Heights':13728, 'Kashmere Gardens':10055, 'Kingwood Area':62067, 'Lake Houston':22280, 'Langwood':9744, 'Lawndale / Wayside':12982, 'Lazy Brook / Timbergrove':13099, 'Macgregor':18459, 'Magnolia Park':16999, 'Meadowbrook / Allendale':24134, 'Medical Center Area':2717, 'Memorial':47604, 'Meyerland Area':21445, 'Mid West':50017, 'Midtown':8597, 'Minnetex':6303, 'Museum Park':5509, 'Neartown - Montrose':31037, 'Northshore':28790, 'Northside Village':27348, 'Northside/Northline':59410, 'Ost / South Union':19141, 'Park Place':9898, 'Pecan Park':16245, 'Pleasantville Area':2860, 'Second Ward':13139, 'Settegast':2981, 'Sharpstown':77220, 'South Acres / Crestmont Park':19137, 'South Belt / Ellington':64667, 'South Main':6006, 'South Park':21208, 'Spring Branch Central':28080, 'Spring Branch East':26877, 'Spring Branch North':20942, 'Spring Branch West':31878, 'Sunnyside':20071, 'Trinity / Houston Gardens':15798, 'University Place':16342, 'Washington Avenue Coalition / Memorial Park':29033, 'Westbranch':3633, 'Westbury':20963, 'Westchase':29149, 'Westwood':19530, 'Willow Meadows / Willowbend Area':14014, 'Willowbrook':8509}\n",
    "def get_population(neighborhood,population):\n",
    "    if neighborhood in population.keys():\n",
    "        return population[neighborhood]\n",
    "    else:\n",
    "        return 0\n",
    "calls[\"POPULATION\"] = calls['R_NEIGHBORHOOD'].apply(lambda x:get_population(x,Population))\n",
    "#Revise department\n",
    "def get_department(department):\n",
    "    return department[department.find(' ')+1:]\n",
    "calls[\"R_DEPARTMENT\"] = calls['DEPARTMENT'].apply(lambda x:get_department(x))\n",
    "#Filter Data\n",
    "filteredcalls  = calls[(calls[\"Class\"] != \"NI\") & (calls['R_NEIGHBORHOOD']!='Unknown') & (calls['R_NEIGHBORHOOD']!='')]\n",
    "filteredcalls = filteredcalls.drop(['NEIGHBORHOOD'],axis = 1)\n",
    "filteredcalls = filteredcalls.drop(['DEPARTMENT'],axis = 1)\n",
    "filteredcalls = filteredcalls.rename(columns={'R_NEIGHBORHOOD':'NEIGHBORHOOD'})\n",
    "filteredcalls = filteredcalls.rename(columns={'R_DEPARTMENT':'DEPARTMENT'})\n",
    "#Keep relevant columns\n",
    "filteredcalls= filteredcalls[['CASE NUMBER','COUNTY','NEIGHBORHOOD','DEPARTMENT','DIVISION','SR TYPE','SR LOCATION','STATUS','SR CREATE DATE','DUE DATE','DATE CLOSED','LATITUDE','LONGITUDE','Channel Type','Class','POPULATION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Counts\n",
    "Incidents = pd.crosstab(filteredcalls.NEIGHBORHOOD,filteredcalls.Class)\n",
    "Incidents['RoadsPerCapita'] = Incidents.apply(lambda x:x.RoadServices/get_population(x.name,Population),axis=1)\n",
    "Incidents['SafetyPerCapita'] = Incidents.apply(lambda x:x.Safety/get_population(x.name,Population),axis=1)\n",
    "Incidents['TrashPerCapita'] = Incidents.apply(lambda x:x.Trash/get_population(x.name,Population),axis=1)\n",
    "Incidents['WaterPerCapita'] = Incidents.apply(lambda x:x.WaterUtility/get_population(x.name,Population),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Setup\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PerCapitaIncidents = Incidents[['RoadsPerCapita','SafetyPerCapita','TrashPerCapita','WaterPerCapita']]\n",
    "x = PerCapitaIncidents.loc[:,: ].values\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Score (0 is most desirable, 1 is least )\n",
    "p1m = principalDf['principal component 1'].min()\n",
    "p1M = principalDf['principal component 1'].max()\n",
    "principalDf['Score'] = principalDf['principal component 1'].apply(lambda x:(x-p1m)/(p1M-p1m))\n",
    "def get_score(number,df):\n",
    "    return df['Score'][number]\n",
    "Incidents['Count'] = np.arange(len(Incidents))\n",
    "Incidents['Score'] = Incidents['Count'].apply(lambda x: get_score(x,principalDf) )\n",
    "filteredcalls['OverallScore'] = filteredcalls.NEIGHBORHOOD.apply(lambda x:Incidents['Score'][x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredcalls.to_csv(datadestination,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA plots and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Plot\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (16,16))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 28)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 28)\n",
    "ax.set_title('2 component PCA', fontsize = 28)\n",
    "ax.scatter(principalDf.loc[:, 'principal component 1']\n",
    "           , principalDf.loc[:, 'principal component 2']\n",
    "           , c = 'b'\n",
    "           , s = 50)\n",
    "Interesting = [[4, 15, 20, 49, 52, 56, 66, 72, 79, 81],[0.07,0.07,-0.5,0.07,0.07,0.07,0.07,0.07,0.07,-1.3],[0.05,0.05,0.1,0.05,0.05,0.05,0.05,0.05,-0.15,-0.15]]\n",
    "Interesting2 = [[1, 40, 45, 68],[-0.2,-0.16,-0.3,-0.7],[0.05,-0.16,-0.2,0.1]]\n",
    "for i in range(len(Interesting[0])):\n",
    "    ax.text(principalDf['principal component 1'][Interesting[0][i]]+Interesting[1][i],principalDf['principal component 2'][Interesting[0][i]]+Interesting[2][i],PerCapitaIncidents.index[Interesting[0][i]],fontsize=22)\n",
    "        #ax.annotate(PerCapitaIncidents.index[i], (principalDf['principal component 1'][i]+.07,principalDf['principal component 2'][i]+.05))\n",
    "for i in range(len(Interesting2[0])):#range(PerCapitaIncidents.index.size):\n",
    "    ax.text(principalDf['principal component 1'][Interesting2[0][i]]+Interesting2[1][i],principalDf['principal component 2'][Interesting2[0][i]]+Interesting2[2][i],PerCapitaIncidents.index[Interesting2[0][i]],fontsize=22)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation between components and variables\n",
    "loadings = pca.components_\n",
    "num_pc = pca.n_features_\n",
    "pc_list = [\"PC\"+str(i) for i in list(range(1, num_pc+1))]\n",
    "loadings_df = pd.DataFrame.from_dict(dict(zip(pc_list, loadings)))\n",
    "loadings_df['variable'] = PerCapitaIncidents.columns.values\n",
    "loadings_df = loadings_df.set_index('variable')\n",
    "print(loadings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
